<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on German Martinez</title>
    <link>http://localhost:1313/projects/</link>
    <description>Recent content in Projects on German Martinez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/projects/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AdventureWorks Sales Analysis and Dashboard</title>
      <link>http://localhost:1313/projects/adventureworks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/adventureworks/</guid>
      <description>Business Request &amp;amp; User Stories The business request for this project was an executive sales report for sales managers. Based on the request that was made from the business we following user stories were defined to fulfill delivery and ensure that acceptance criteriaâ€™s were maintained throughout the project.&#xA;As a (role) I want (request / demand) So that I can (user value) Acceptance Criteria Sales Manager A dashboard overview of internet sales Follow sales over time against budget A Power Bi dashboard with graphs and KPIs comparing sales against budget.</description>
    </item>
    <item>
      <title>K Nearest Neighbour Sentiment Analysis with Gzip Embeddings</title>
      <link>http://localhost:1313/projects/gzip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/gzip/</guid>
      <description>Imports import gzip import time import pickle import multiprocessing import warnings import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score Load Dataset # There are a total of 24639 samples n_samples = 5000 df = pd.read_csv(&amp;#39;/kaggle/input/sentiment-and-emotions-of-tweets/sentiment-emotion-labelled_Dell_tweets.csv&amp;#39;) df = df.truncate(0, n_samples) X = df[&amp;#39;Text&amp;#39;] X.head() y = df[&amp;#39;sentiment&amp;#39;] y.head() Data Cleaning and Preparation X = X.str.replace(r&amp;#39;@[^ ]+&amp;#39;, &amp;#39;&amp;#39;, regex=True) # Remove tagged users X = X.</description>
    </item>
    <item>
      <title>Logistic Regression for Heart Attacks</title>
      <link>http://localhost:1313/projects/heartattack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/heartattack/</guid>
      <description>Abstract This code segment demonstrates the implementation of a logistic regression model for heart attack prediction using the Heart Attack Analysis and Prediction Dataset.&#xA;Imports import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report Load Dataset df = pd.read_csv(&amp;#34;/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv&amp;#34;) df X = df.drop([&amp;#39;output&amp;#39;], axis=1) y = df[&amp;#39;output&amp;#39;] Scaler scaler = StandardScaler() scaler.</description>
    </item>
    <item>
      <title>Visual Transformer from Scratch for Pneumonia Detection</title>
      <link>http://localhost:1313/projects/vit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/vit/</guid>
      <description>Abstract This code implements a Vision Transformer (ViT) model for image classification, comprising custom layers such as PreNorm, Multi-Layer Perceptron (MLP), Attention, and Transformer, along with data preprocessing functions. The ViT model architecture consists of patch embedding, positional embedding, multi-head self-attention mechanism, and a multi-layer perceptron for feature extraction and classification. The code also includes functions for loading and preprocessing image data from a given dataset. Training is performed using Sparse Categorical Crossentropy loss and Adam optimizer, with validation accuracy monitored during training.</description>
    </item>
  </channel>
</rss>
